{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to move WP_Increase column to the end\n",
    "data = pd.read_csv('coinbase_data_clean.csv',index_col='Timestamp')\n",
    "output = data['WP_Increase']\n",
    "data.drop(labels=['WP_Increase','Unnamed: 0'],axis=1,inplace=True)\n",
    "data.insert(len(data.columns),'WP_Increase',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>Volume_USD</th>\n",
       "      <th>Weighted_Price</th>\n",
       "      <th>ma10</th>\n",
       "      <th>ma50</th>\n",
       "      <th>ma100</th>\n",
       "      <th>Ma10_WP_Increase</th>\n",
       "      <th>Ma50_WP_Increase</th>\n",
       "      <th>Ma100_WP_Increase</th>\n",
       "      <th>rsi</th>\n",
       "      <th>RSI_GreaterThan_50</th>\n",
       "      <th>WP_Increase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-04-13</th>\n",
       "      <td>237.57</td>\n",
       "      <td>238.00</td>\n",
       "      <td>220.77</td>\n",
       "      <td>225.73</td>\n",
       "      <td>11641.757952</td>\n",
       "      <td>2.682148e+06</td>\n",
       "      <td>233.545702</td>\n",
       "      <td>246.729993</td>\n",
       "      <td>260.814036</td>\n",
       "      <td>258.526647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.866182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-14</th>\n",
       "      <td>225.42</td>\n",
       "      <td>226.90</td>\n",
       "      <td>216.92</td>\n",
       "      <td>221.05</td>\n",
       "      <td>12054.596084</td>\n",
       "      <td>2.666821e+06</td>\n",
       "      <td>221.570503</td>\n",
       "      <td>243.495826</td>\n",
       "      <td>260.497650</td>\n",
       "      <td>257.392352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.713888</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-15</th>\n",
       "      <td>221.05</td>\n",
       "      <td>224.52</td>\n",
       "      <td>218.09</td>\n",
       "      <td>224.35</td>\n",
       "      <td>8708.367431</td>\n",
       "      <td>1.933906e+06</td>\n",
       "      <td>222.241195</td>\n",
       "      <td>240.101389</td>\n",
       "      <td>260.158047</td>\n",
       "      <td>255.836215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.532087</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-16</th>\n",
       "      <td>224.35</td>\n",
       "      <td>230.75</td>\n",
       "      <td>223.66</td>\n",
       "      <td>229.45</td>\n",
       "      <td>8248.389761</td>\n",
       "      <td>1.881515e+06</td>\n",
       "      <td>227.817999</td>\n",
       "      <td>236.953587</td>\n",
       "      <td>259.940846</td>\n",
       "      <td>254.336212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.118478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-17</th>\n",
       "      <td>229.45</td>\n",
       "      <td>230.08</td>\n",
       "      <td>220.46</td>\n",
       "      <td>223.62</td>\n",
       "      <td>7338.967548</td>\n",
       "      <td>1.652133e+06</td>\n",
       "      <td>224.980171</td>\n",
       "      <td>233.883770</td>\n",
       "      <td>259.698071</td>\n",
       "      <td>252.815013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.499774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>3691.87</td>\n",
       "      <td>3841.17</td>\n",
       "      <td>3651.02</td>\n",
       "      <td>3826.10</td>\n",
       "      <td>10347.590883</td>\n",
       "      <td>3.840389e+07</td>\n",
       "      <td>3700.539528</td>\n",
       "      <td>3819.206854</td>\n",
       "      <td>4052.495977</td>\n",
       "      <td>5238.905840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.244528</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>3826.10</td>\n",
       "      <td>3916.57</td>\n",
       "      <td>3770.07</td>\n",
       "      <td>3890.79</td>\n",
       "      <td>9611.282751</td>\n",
       "      <td>3.688630e+07</td>\n",
       "      <td>3823.152158</td>\n",
       "      <td>3803.664620</td>\n",
       "      <td>4003.122784</td>\n",
       "      <td>5210.750806</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.696821</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>3890.80</td>\n",
       "      <td>3893.80</td>\n",
       "      <td>3758.07</td>\n",
       "      <td>3787.57</td>\n",
       "      <td>8840.254922</td>\n",
       "      <td>3.382343e+07</td>\n",
       "      <td>3829.900978</td>\n",
       "      <td>3774.049765</td>\n",
       "      <td>3959.304746</td>\n",
       "      <td>5184.900157</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.938112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>3787.57</td>\n",
       "      <td>3849.00</td>\n",
       "      <td>3730.00</td>\n",
       "      <td>3820.82</td>\n",
       "      <td>8950.110359</td>\n",
       "      <td>3.387391e+07</td>\n",
       "      <td>3785.337456</td>\n",
       "      <td>3775.216241</td>\n",
       "      <td>3925.107855</td>\n",
       "      <td>5158.127796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.290909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>3820.82</td>\n",
       "      <td>3874.12</td>\n",
       "      <td>3775.00</td>\n",
       "      <td>3798.62</td>\n",
       "      <td>6057.934757</td>\n",
       "      <td>2.322994e+07</td>\n",
       "      <td>3834.565401</td>\n",
       "      <td>3781.169329</td>\n",
       "      <td>3891.174072</td>\n",
       "      <td>5131.280787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.243372</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1364 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open     High      Low    Close    Volume_BTC    Volume_USD  \\\n",
       "Timestamp                                                                    \n",
       "2015-04-13   237.57   238.00   220.77   225.73  11641.757952  2.682148e+06   \n",
       "2015-04-14   225.42   226.90   216.92   221.05  12054.596084  2.666821e+06   \n",
       "2015-04-15   221.05   224.52   218.09   224.35   8708.367431  1.933906e+06   \n",
       "2015-04-16   224.35   230.75   223.66   229.45   8248.389761  1.881515e+06   \n",
       "2015-04-17   229.45   230.08   220.46   223.62   7338.967548  1.652133e+06   \n",
       "...             ...      ...      ...      ...           ...           ...   \n",
       "2019-01-01  3691.87  3841.17  3651.02  3826.10  10347.590883  3.840389e+07   \n",
       "2019-01-02  3826.10  3916.57  3770.07  3890.79   9611.282751  3.688630e+07   \n",
       "2019-01-03  3890.80  3893.80  3758.07  3787.57   8840.254922  3.382343e+07   \n",
       "2019-01-04  3787.57  3849.00  3730.00  3820.82   8950.110359  3.387391e+07   \n",
       "2019-01-05  3820.82  3874.12  3775.00  3798.62   6057.934757  2.322994e+07   \n",
       "\n",
       "            Weighted_Price         ma10         ma50        ma100  \\\n",
       "Timestamp                                                           \n",
       "2015-04-13      233.545702   246.729993   260.814036   258.526647   \n",
       "2015-04-14      221.570503   243.495826   260.497650   257.392352   \n",
       "2015-04-15      222.241195   240.101389   260.158047   255.836215   \n",
       "2015-04-16      227.817999   236.953587   259.940846   254.336212   \n",
       "2015-04-17      224.980171   233.883770   259.698071   252.815013   \n",
       "...                    ...          ...          ...          ...   \n",
       "2019-01-01     3700.539528  3819.206854  4052.495977  5238.905840   \n",
       "2019-01-02     3823.152158  3803.664620  4003.122784  5210.750806   \n",
       "2019-01-03     3829.900978  3774.049765  3959.304746  5184.900157   \n",
       "2019-01-04     3785.337456  3775.216241  3925.107855  5158.127796   \n",
       "2019-01-05     3834.565401  3781.169329  3891.174072  5131.280787   \n",
       "\n",
       "            Ma10_WP_Increase  Ma50_WP_Increase  Ma100_WP_Increase        rsi  \\\n",
       "Timestamp                                                                      \n",
       "2015-04-13                 0                 0                  0  32.866182   \n",
       "2015-04-14                 0                 0                  0  26.713888   \n",
       "2015-04-15                 0                 0                  0  27.532087   \n",
       "2015-04-16                 0                 0                  0  34.118478   \n",
       "2015-04-17                 0                 0                  0  32.499774   \n",
       "...                      ...               ...                ...        ...   \n",
       "2019-01-01                 0                 0                  0  45.244528   \n",
       "2019-01-02                 1                 0                  0  49.696821   \n",
       "2019-01-03                 1                 0                  0  49.938112   \n",
       "2019-01-04                 1                 0                  0  48.290909   \n",
       "2019-01-05                 1                 0                  0  50.243372   \n",
       "\n",
       "            RSI_GreaterThan_50  WP_Increase  \n",
       "Timestamp                                    \n",
       "2015-04-13                   0            0  \n",
       "2015-04-14                   0            1  \n",
       "2015-04-15                   0            1  \n",
       "2015-04-16                   0            0  \n",
       "2015-04-17                   0            0  \n",
       "...                        ...          ...  \n",
       "2019-01-01                   0            1  \n",
       "2019-01-02                   0            1  \n",
       "2019-01-03                   0            0  \n",
       "2019-01-04                   0            1  \n",
       "2019-01-05                   1            1  \n",
       "\n",
       "[1364 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index = pd.to_datetime(data.index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1364, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_size = int(.3*len(data))\n",
    "train_data = data[:-test_data_size] # start from index 0 to int(.3*len(data)) before final row\n",
    "test_data = data[-test_data_size:] # start from index int(.3*len(data)) onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(955, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>Volume_USD</th>\n",
       "      <th>Weighted_Price</th>\n",
       "      <th>ma10</th>\n",
       "      <th>ma50</th>\n",
       "      <th>ma100</th>\n",
       "      <th>Ma10_WP_Increase</th>\n",
       "      <th>Ma50_WP_Increase</th>\n",
       "      <th>Ma100_WP_Increase</th>\n",
       "      <th>rsi</th>\n",
       "      <th>RSI_GreaterThan_50</th>\n",
       "      <th>WP_Increase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-04-13</th>\n",
       "      <td>237.57</td>\n",
       "      <td>238.00</td>\n",
       "      <td>220.77</td>\n",
       "      <td>225.73</td>\n",
       "      <td>11641.757952</td>\n",
       "      <td>2.682148e+06</td>\n",
       "      <td>233.545702</td>\n",
       "      <td>246.729993</td>\n",
       "      <td>260.814036</td>\n",
       "      <td>258.526647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.866182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-14</th>\n",
       "      <td>225.42</td>\n",
       "      <td>226.90</td>\n",
       "      <td>216.92</td>\n",
       "      <td>221.05</td>\n",
       "      <td>12054.596084</td>\n",
       "      <td>2.666821e+06</td>\n",
       "      <td>221.570503</td>\n",
       "      <td>243.495826</td>\n",
       "      <td>260.497650</td>\n",
       "      <td>257.392352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.713888</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-15</th>\n",
       "      <td>221.05</td>\n",
       "      <td>224.52</td>\n",
       "      <td>218.09</td>\n",
       "      <td>224.35</td>\n",
       "      <td>8708.367431</td>\n",
       "      <td>1.933906e+06</td>\n",
       "      <td>222.241195</td>\n",
       "      <td>240.101389</td>\n",
       "      <td>260.158047</td>\n",
       "      <td>255.836215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.532087</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-16</th>\n",
       "      <td>224.35</td>\n",
       "      <td>230.75</td>\n",
       "      <td>223.66</td>\n",
       "      <td>229.45</td>\n",
       "      <td>8248.389761</td>\n",
       "      <td>1.881515e+06</td>\n",
       "      <td>227.817999</td>\n",
       "      <td>236.953587</td>\n",
       "      <td>259.940846</td>\n",
       "      <td>254.336212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.118478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-17</th>\n",
       "      <td>229.45</td>\n",
       "      <td>230.08</td>\n",
       "      <td>220.46</td>\n",
       "      <td>223.62</td>\n",
       "      <td>7338.967548</td>\n",
       "      <td>1.652133e+06</td>\n",
       "      <td>224.980171</td>\n",
       "      <td>233.883770</td>\n",
       "      <td>259.698071</td>\n",
       "      <td>252.815013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.499774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18</th>\n",
       "      <td>7714.70</td>\n",
       "      <td>7847.98</td>\n",
       "      <td>7502.00</td>\n",
       "      <td>7777.01</td>\n",
       "      <td>14531.700663</td>\n",
       "      <td>1.116767e+08</td>\n",
       "      <td>7714.778844</td>\n",
       "      <td>6987.605861</td>\n",
       "      <td>5909.709699</td>\n",
       "      <td>5025.846459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66.049068</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19</th>\n",
       "      <td>7777.01</td>\n",
       "      <td>8098.62</td>\n",
       "      <td>7700.00</td>\n",
       "      <td>8031.82</td>\n",
       "      <td>14085.483398</td>\n",
       "      <td>1.115954e+08</td>\n",
       "      <td>7839.763237</td>\n",
       "      <td>7046.875070</td>\n",
       "      <td>5981.112282</td>\n",
       "      <td>5069.077280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67.304111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>8031.83</td>\n",
       "      <td>8293.25</td>\n",
       "      <td>7969.00</td>\n",
       "      <td>8256.01</td>\n",
       "      <td>15479.896162</td>\n",
       "      <td>1.264800e+08</td>\n",
       "      <td>8126.735070</td>\n",
       "      <td>7162.908703</td>\n",
       "      <td>6057.401394</td>\n",
       "      <td>5112.434711</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.042417</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-21</th>\n",
       "      <td>8256.01</td>\n",
       "      <td>8375.00</td>\n",
       "      <td>7802.99</td>\n",
       "      <td>8109.00</td>\n",
       "      <td>29504.806698</td>\n",
       "      <td>2.396179e+08</td>\n",
       "      <td>8185.441891</td>\n",
       "      <td>7325.662864</td>\n",
       "      <td>6132.887809</td>\n",
       "      <td>5153.875284</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.585154</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22</th>\n",
       "      <td>8109.00</td>\n",
       "      <td>8298.98</td>\n",
       "      <td>8103.13</td>\n",
       "      <td>8250.00</td>\n",
       "      <td>13107.940089</td>\n",
       "      <td>1.074391e+08</td>\n",
       "      <td>8210.158268</td>\n",
       "      <td>7536.938053</td>\n",
       "      <td>6210.741840</td>\n",
       "      <td>5194.201667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.824804</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>955 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open     High      Low    Close    Volume_BTC    Volume_USD  \\\n",
       "Timestamp                                                                    \n",
       "2015-04-13   237.57   238.00   220.77   225.73  11641.757952  2.682148e+06   \n",
       "2015-04-14   225.42   226.90   216.92   221.05  12054.596084  2.666821e+06   \n",
       "2015-04-15   221.05   224.52   218.09   224.35   8708.367431  1.933906e+06   \n",
       "2015-04-16   224.35   230.75   223.66   229.45   8248.389761  1.881515e+06   \n",
       "2015-04-17   229.45   230.08   220.46   223.62   7338.967548  1.652133e+06   \n",
       "...             ...      ...      ...      ...           ...           ...   \n",
       "2017-11-18  7714.70  7847.98  7502.00  7777.01  14531.700663  1.116767e+08   \n",
       "2017-11-19  7777.01  8098.62  7700.00  8031.82  14085.483398  1.115954e+08   \n",
       "2017-11-20  8031.83  8293.25  7969.00  8256.01  15479.896162  1.264800e+08   \n",
       "2017-11-21  8256.01  8375.00  7802.99  8109.00  29504.806698  2.396179e+08   \n",
       "2017-11-22  8109.00  8298.98  8103.13  8250.00  13107.940089  1.074391e+08   \n",
       "\n",
       "            Weighted_Price         ma10         ma50        ma100  \\\n",
       "Timestamp                                                           \n",
       "2015-04-13      233.545702   246.729993   260.814036   258.526647   \n",
       "2015-04-14      221.570503   243.495826   260.497650   257.392352   \n",
       "2015-04-15      222.241195   240.101389   260.158047   255.836215   \n",
       "2015-04-16      227.817999   236.953587   259.940846   254.336212   \n",
       "2015-04-17      224.980171   233.883770   259.698071   252.815013   \n",
       "...                    ...          ...          ...          ...   \n",
       "2017-11-18     7714.778844  6987.605861  5909.709699  5025.846459   \n",
       "2017-11-19     7839.763237  7046.875070  5981.112282  5069.077280   \n",
       "2017-11-20     8126.735070  7162.908703  6057.401394  5112.434711   \n",
       "2017-11-21     8185.441891  7325.662864  6132.887809  5153.875284   \n",
       "2017-11-22     8210.158268  7536.938053  6210.741840  5194.201667   \n",
       "\n",
       "            Ma10_WP_Increase  Ma50_WP_Increase  Ma100_WP_Increase        rsi  \\\n",
       "Timestamp                                                                      \n",
       "2015-04-13                 0                 0                  0  32.866182   \n",
       "2015-04-14                 0                 0                  0  26.713888   \n",
       "2015-04-15                 0                 0                  0  27.532087   \n",
       "2015-04-16                 0                 0                  0  34.118478   \n",
       "2015-04-17                 0                 0                  0  32.499774   \n",
       "...                      ...               ...                ...        ...   \n",
       "2017-11-18                 1                 1                  1  66.049068   \n",
       "2017-11-19                 1                 1                  1  67.304111   \n",
       "2017-11-20                 1                 1                  1  70.042417   \n",
       "2017-11-21                 1                 1                  1  70.585154   \n",
       "2017-11-22                 1                 1                  1  70.824804   \n",
       "\n",
       "            RSI_GreaterThan_50  WP_Increase  \n",
       "Timestamp                                    \n",
       "2015-04-13                   0            0  \n",
       "2015-04-14                   0            1  \n",
       "2015-04-15                   0            1  \n",
       "2015-04-16                   0            0  \n",
       "2015-04-17                   0            0  \n",
       "...                        ...          ...  \n",
       "2017-11-18                   1            1  \n",
       "2017-11-19                   1            1  \n",
       "2017-11-20                   1            1  \n",
       "2017-11-21                   1            1  \n",
       "2017-11-22                   1            0  \n",
       "\n",
       "[955 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize columns\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.28284555e-03, 1.71268170e-03, 2.72378247e-02, ...,\n",
       "         2.24121409e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[1.77256257e-03, 3.50878915e-04, 2.67626961e-02, ...,\n",
       "         1.47185735e-01, 0.00000000e+00, 1.00000000e+00]],\n",
       "\n",
       "       [[1.22935791e-03, 5.88887689e-05, 2.69070858e-02, ...,\n",
       "         1.57417479e-01, 0.00000000e+00, 1.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[9.72133725e-01, 9.89970507e-01, 9.83447015e-01, ...,\n",
       "         6.89017716e-01, 1.00000000e+00, 1.00000000e+00]],\n",
       "\n",
       "       [[1.00000000e+00, 1.00000000e+00, 9.62959718e-01, ...,\n",
       "         6.95804751e-01, 1.00000000e+00, 1.00000000e+00]],\n",
       "\n",
       "       [[9.81726198e-01, 9.90673491e-01, 1.00000000e+00, ...,\n",
       "         6.98801622e-01, 1.00000000e+00, 0.00000000e+00]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(train_data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window\n",
    "- testing increments of data to find best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data,seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    \n",
    "    for i in range(len(data)-seq_length-1): # iterates through seq and starts at beginning of next sequence\n",
    "        x = data[i:(i+seq_length)] # get all columns except last\n",
    "        y = data[i+seq_length] # exactly the next index after x\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    \n",
    "    return np.array(xs),np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 5 # train model based on sequences of 5 days\n",
    "\n",
    "X_train, y_train = sliding_windows(train_data,seq_length)\n",
    "X_test, y_test = sliding_windows(test_data,seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949, 5, 16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15184])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.28284555e-03, 1.71268170e-03, 2.72378247e-02, 1.81109654e-03,\n",
       "         6.64686733e-02, 7.53316718e-03, 2.19683644e-03, 2.79194145e-03,\n",
       "         4.56274981e-03, 4.08329213e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.24121409e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.77256257e-03, 3.50878915e-04, 2.67626961e-02, 1.22935791e-03,\n",
       "         6.89728624e-02, 7.48174794e-03, 6.98845775e-04, 2.34954842e-03,\n",
       "         4.50981768e-03, 3.85441496e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 1.47185735e-01, 0.00000000e+00, 1.00000000e+00],\n",
       "        [1.22935791e-03, 5.88887689e-05, 2.69070858e-02, 1.63955823e-03,\n",
       "         4.86753452e-02, 5.02303611e-03, 7.82743426e-04, 1.88523236e-03,\n",
       "         4.45300143e-03, 3.54041881e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 1.57417479e-01, 0.00000000e+00, 1.00000000e+00],\n",
       "        [1.63955823e-03, 8.23215916e-04, 2.75944796e-02, 2.27350417e-03,\n",
       "         4.58852176e-02, 4.84727998e-03, 1.48035185e-03, 1.45465293e-03,\n",
       "         4.41666313e-03, 3.23774929e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.39781620e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.27350417e-03, 7.41017009e-04, 2.71995676e-02, 1.54881695e-03,\n",
       "         4.03688543e-02, 4.07777112e-03, 1.12536491e-03, 1.03474092e-03,\n",
       "         4.37604618e-03, 2.93080307e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.19539401e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[1.77256257e-03, 3.50878915e-04, 2.67626961e-02, 1.22935791e-03,\n",
       "         6.89728624e-02, 7.48174794e-03, 6.98845775e-04, 2.34954842e-03,\n",
       "         4.50981768e-03, 3.85441496e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 1.47185735e-01, 0.00000000e+00, 1.00000000e+00],\n",
       "        [1.22935791e-03, 5.88887689e-05, 2.69070858e-02, 1.63955823e-03,\n",
       "         4.86753452e-02, 5.02303611e-03, 7.82743426e-04, 1.88523236e-03,\n",
       "         4.45300143e-03, 3.54041881e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 1.57417479e-01, 0.00000000e+00, 1.00000000e+00],\n",
       "        [1.63955823e-03, 8.23215916e-04, 2.75944796e-02, 2.27350417e-03,\n",
       "         4.58852176e-02, 4.84727998e-03, 1.48035185e-03, 1.45465293e-03,\n",
       "         4.41666313e-03, 3.23774929e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.39781620e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.27350417e-03, 7.41017009e-04, 2.71995676e-02, 1.54881695e-03,\n",
       "         4.03688543e-02, 4.07777112e-03, 1.12536491e-03, 1.03474092e-03,\n",
       "         4.37604618e-03, 2.93080307e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.19539401e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.54011573e-03, 0.00000000e+00, 2.74118328e-02, 1.59853820e-03,\n",
       "         2.31460500e-02, 1.90631914e-03, 9.31442523e-04, 6.68989882e-04,\n",
       "         4.28376597e-03, 2.61891275e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.08503864e-01, 0.00000000e+00, 1.00000000e+00]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2] # taking first and second sequence - expect 5 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5401e-03, 0.0000e+00, 2.7412e-02,  ..., 2.0850e-01, 0.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [1.6010e-03, 3.2880e-04, 2.7567e-02,  ..., 2.2816e-01, 0.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [1.5998e-03, 4.1836e-04, 2.7569e-02,  ..., 2.3440e-01, 0.0000e+00,\n",
       "         1.0000e+00],\n",
       "        ...,\n",
       "        [9.4046e-01, 9.6609e-01, 9.5025e-01,  ..., 6.5477e-01, 1.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [9.7213e-01, 9.8997e-01, 9.8345e-01,  ..., 6.8902e-01, 1.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [1.0000e+00, 1.0000e+00, 9.6296e-01,  ..., 6.9580e-01, 1.0000e+00,\n",
       "         1.0000e+00]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1880, 1.1981, 1.1978,  ..., 0.8541, 1.0000, 1.0000],\n",
       "        [1.2104, 1.3816, 1.0608,  ..., 0.8862, 1.0000, 0.0000],\n",
       "        [1.2069, 1.3036, 1.1274,  ..., 0.7596, 1.0000, 1.0000],\n",
       "        ...,\n",
       "        [0.4493, 0.4530, 0.4653,  ..., 0.4346, 0.0000, 1.0000],\n",
       "        [0.4574, 0.4502, 0.4638,  ..., 0.4376, 0.0000, 0.0000],\n",
       "        [0.4446, 0.4447, 0.4603,  ..., 0.4170, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Libraries\n",
    "import torch\n",
    "import torch.nn as nn # helps create models\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5401e-03, 0.0000e+00, 2.7412e-02,  ..., 2.0850e-01, 0.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [1.6010e-03, 3.2880e-04, 2.7567e-02,  ..., 2.2816e-01, 0.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [1.5998e-03, 4.1836e-04, 2.7569e-02,  ..., 2.3440e-01, 0.0000e+00,\n",
       "         1.0000e+00],\n",
       "        ...,\n",
       "        [9.4046e-01, 9.6609e-01, 9.5025e-01,  ..., 6.5477e-01, 1.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [9.7213e-01, 9.8997e-01, 9.8345e-01,  ..., 6.8902e-01, 1.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [1.0000e+00, 1.0000e+00, 9.6296e-01,  ..., 6.9580e-01, 1.0000e+00,\n",
       "         1.0000e+00]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15184])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yo = y_train.flatten()\n",
    "yo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,hidden_dim,seq_len,num_layers=2):\n",
    "        super(LSTM,self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # build out LSTM layer and signmoid (output) layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = input_dim,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = num_layers,\n",
    "            dropout=.5\n",
    "        )\n",
    "        \n",
    "        #sigmoid layer\n",
    "        # self.linear = nn.Linear(in_features=hidden_dim,out_features=2) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def reset_hidden_state(self):\n",
    "        self.hidden = (\n",
    "            torch.zeros(self.num_layers,self.seq_len,self.hidden_dim),\n",
    "            torch.zeros(self.num_layers,self.seq_len,self.hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self,input):\n",
    "        lstm_out, _ = self.lstm(\n",
    "            input.view(len(input),self.seq_len,-1),\n",
    "            self.hidden\n",
    "        )\n",
    "        y_pred = self.sigmoid(\n",
    "            lstm_out.view(self.seq_len,len(input),self.hidden_dim)[-1] # pull from last timestep\n",
    "        )\n",
    "    \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_data,train_labels,test_data=None,test_labels=None):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "    \n",
    "    num_epochs = 60\n",
    "    train_hist = np.zeros(num_epochs)\n",
    "    test_hist = np.zeros(num_epochs)\n",
    "    \n",
    "    # reset state of inputs\n",
    "    for i in range(num_epochs):\n",
    "        model.reset_hidden_state()\n",
    "        \n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred,y_train.flatten())\n",
    "        \n",
    "        if test_data is not None:\n",
    "            with torch.no_grad():\n",
    "                y_test_pred = model(X_test)\n",
    "                test_loss = loss_fn(y_test_pred,y_test)\n",
    "            test_hist[i] = test_loss.item()\n",
    "            \n",
    "            # print results every 10 epochs\n",
    "            if i % 10 == 0:\n",
    "                print('Epoch number:{} train loss: {} test loss: {}'.format(i,loss.item(),test_loss.item()))\n",
    "        elif i % 10 == 0:\n",
    "            print('Epoch number:{} train loss: {}'.format(i,loss.item()))\n",
    "            \n",
    "        train_hist[i] = loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    return model.eval(), train_hist, test_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(16,512,seq_len=seq_length,num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (949) to match target batch_size (15184).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-91b85c7053f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_hist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-57-01d21682f4c4>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_data, train_labels, test_data, test_labels)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fastai_v1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fastai_v1\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m    932\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fastai_v1\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2316\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2317\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fastai_v1\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2111\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2112\u001b[1;33m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0m\u001b[0;32m   2113\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   2114\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (949) to match target batch_size (15184)."
     ]
    }
   ],
   "source": [
    "model,train_hist,test_hist = train_model(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15184"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "949*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai v1",
   "language": "python",
   "name": "fastai_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
