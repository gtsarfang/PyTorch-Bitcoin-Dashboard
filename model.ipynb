{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coinbase_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to drop timestamp to be able to convert to tensor\n",
    "X=df.drop(['WP_Increase','Timestamp'],axis=1).values\n",
    "y = df['WP_Increase'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.000e+00, 2.000e+00, 3.000e+00, ..., 1.362e+03, 1.363e+03,\n",
       "       1.364e+03])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Libraries\n",
    "import torch\n",
    "import torch.nn as nn # helps create models\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert arrays to tensors for Pytorch to process\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "class ANN(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_features=16,hidden1=20,hidden2=20,out_features=2):\n",
    "        super().__init__()\n",
    "        self.f_connected1 = nn.Linear(input_features,hidden1) # connect input to hidden layer 1\n",
    "        self.f_connected2 = nn.Linear(hidden1,hidden2) # connect hidden layer 1 to hiddent layer 2\n",
    "        self.out = nn.Linear(hidden2,out_features) # connect hidden 2 to output\n",
    "        \n",
    "    def forward(self,x): # forward propogation\n",
    "            x = F.relu(self.f_connected1(x)) \n",
    "            x = F.relu(self.f_connected2(x))\n",
    "            x = self.out(x)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantialize ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(20)\n",
    "model = ANN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ANN(\n",
       "  (f_connected1): Linear(in_features=16, out_features=20, bias=True)\n",
       "  (f_connected2): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (out): Linear(in_features=20, out_features=2, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, define optimizer\n",
    "loss_function = nn.CrossEntropyLoss() # useful for multiclassification problem\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number:1 and the loss: 1341637.75\n",
      "Epoch number:11 and the loss: 1557.415283203125\n",
      "Epoch number:21 and the loss: 76183.90625\n",
      "Epoch number:31 and the loss: 41327.015625\n",
      "Epoch number:41 and the loss: 33610.13671875\n",
      "Epoch number:51 and the loss: 26970.359375\n",
      "Epoch number:61 and the loss: 83044.7421875\n",
      "Epoch number:71 and the loss: 28356.701171875\n",
      "Epoch number:81 and the loss: 99426.4296875\n",
      "Epoch number:91 and the loss: 42089.0390625\n",
      "Epoch number:101 and the loss: 46398.640625\n",
      "Epoch number:111 and the loss: 32307.82421875\n",
      "Epoch number:121 and the loss: 76521.0\n",
      "Epoch number:131 and the loss: 11312.3603515625\n",
      "Epoch number:141 and the loss: 45241.6171875\n",
      "Epoch number:151 and the loss: 67218.234375\n",
      "Epoch number:161 and the loss: 38068.8984375\n",
      "Epoch number:171 and the loss: 7295.52978515625\n",
      "Epoch number:181 and the loss: 20495.111328125\n",
      "Epoch number:191 and the loss: 24836.619140625\n",
      "Epoch number:201 and the loss: 7057.51416015625\n",
      "Epoch number:211 and the loss: 16038.8544921875\n",
      "Epoch number:221 and the loss: 4245.43359375\n",
      "Epoch number:231 and the loss: 6211.8505859375\n",
      "Epoch number:241 and the loss: 9839.3212890625\n",
      "Epoch number:251 and the loss: 11699.0927734375\n",
      "Epoch number:261 and the loss: 970.5237426757812\n",
      "Epoch number:271 and the loss: 2432.342041015625\n",
      "Epoch number:281 and the loss: 8559.1962890625\n",
      "Epoch number:291 and the loss: 2800.20458984375\n",
      "Epoch number:301 and the loss: 5033.32373046875\n",
      "Epoch number:311 and the loss: 2607.026611328125\n",
      "Epoch number:321 and the loss: 2900.969482421875\n",
      "Epoch number:331 and the loss: 3554.67138671875\n",
      "Epoch number:341 and the loss: 7276.61572265625\n",
      "Epoch number:351 and the loss: 4699.892578125\n",
      "Epoch number:361 and the loss: 6494.3720703125\n",
      "Epoch number:371 and the loss: 492.2225036621094\n",
      "Epoch number:381 and the loss: 852.4883422851562\n",
      "Epoch number:391 and the loss: 1369.4735107421875\n",
      "Epoch number:401 and the loss: 1562.43701171875\n",
      "Epoch number:411 and the loss: 374.3686828613281\n",
      "Epoch number:421 and the loss: 1479.0289306640625\n",
      "Epoch number:431 and the loss: 2417.122802734375\n",
      "Epoch number:441 and the loss: 1452.7198486328125\n",
      "Epoch number:451 and the loss: 753.2830810546875\n",
      "Epoch number:461 and the loss: 303.7889404296875\n",
      "Epoch number:471 and the loss: 236.41317749023438\n",
      "Epoch number:481 and the loss: 246.92962646484375\n",
      "Epoch number:491 and the loss: 346.6464538574219\n"
     ]
    }
   ],
   "source": [
    "epochs=500\n",
    "final_losses = []\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = loss_function(y_pred,y_train)\n",
    "    final_losses.append(loss)\n",
    "    if i%10 == 1:\n",
    "        print('Epoch number:{} and the loss: {}'.format(i,loss.item()))\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer.zero_grad() # help reduce loss\n",
    "    loss.backward() # backpropogate - find derivative\n",
    "    optimizer.step() # performs single optimization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # plot loss function\n",
    "plt.plot(range(epochs),final_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-102.2191,  265.6334])\n",
      "tensor([-1119.0280,   623.2648])\n",
      "tensor([-44.7216, 278.7504])\n",
      "tensor([-159.0615, -114.6510])\n",
      "tensor([-111.1834,  -79.6264])\n",
      "tensor([-131.3619,  -79.5176])\n",
      "tensor([-113.5029,  -69.6689])\n",
      "tensor([-343.9987,  437.1495])\n",
      "tensor([-97.5559, -61.2306])\n",
      "tensor([-1421.1285,  1135.3644])\n",
      "tensor([-39.3573,   1.8208])\n",
      "tensor([-233.2309,  154.7216])\n",
      "tensor([-23.1581, 247.7904])\n",
      "tensor([-78.9200, -55.0281])\n",
      "tensor([-107.0287,  -67.9812])\n",
      "tensor([-130.3684,  -93.9451])\n",
      "tensor([-77.0007, -51.0757])\n",
      "tensor([-168.4523, -114.9648])\n",
      "tensor([-103.1330,  -61.8801])\n",
      "tensor([-59.1290, -26.5430])\n",
      "tensor([-1094.9508,   870.7980])\n",
      "tensor([-423.7067,  878.3810])\n",
      "tensor([-551.7330,  763.1554])\n",
      "tensor([-60.0252, -24.9548])\n",
      "tensor([-253.0075,  -71.7407])\n",
      "tensor([-80.0262, -36.1859])\n",
      "tensor([-702.8800,  144.4362])\n",
      "tensor([-72.3256, -33.3728])\n",
      "tensor([-72.8561, -46.5679])\n",
      "tensor([-117.3262,  -82.5736])\n",
      "tensor([-862.6735, 1213.0695])\n",
      "tensor([-88.5763, -41.4744])\n",
      "tensor([-156.9574,  -74.6865])\n",
      "tensor([-266.0492,  164.2682])\n",
      "tensor([-437.7155,  522.1339])\n",
      "tensor([-109.6932,  -33.9045])\n",
      "tensor([-45.1525, -13.6817])\n",
      "tensor([-68.8113, -31.3572])\n",
      "tensor([ 52.1783, 239.1442])\n",
      "tensor([-130.1847,  -83.3021])\n",
      "tensor([-205.0814,  162.3214])\n",
      "tensor([-70.7954, -30.6082])\n",
      "tensor([-652.0438, -441.9452])\n",
      "tensor([-92.2059, -59.7897])\n",
      "tensor([-85.2005, -49.9840])\n",
      "tensor([-72.7633, -35.4105])\n",
      "tensor([-45.1858, -30.5071])\n",
      "tensor([-135.2891,  -94.4525])\n",
      "tensor([-259.4874, -139.0719])\n",
      "tensor([-68.8514, -27.8737])\n",
      "tensor([ 66.2173, 228.9167])\n",
      "tensor([-1345.7770,   766.0167])\n",
      "tensor([-68.7145, -47.4338])\n",
      "tensor([-109.9157,  -58.6214])\n",
      "tensor([-333.1183,  135.4757])\n",
      "tensor([-687.2291,  640.6720])\n",
      "tensor([-106.3086,  -73.5334])\n",
      "tensor([-48.4194, -19.5634])\n",
      "tensor([-186.4118,  316.3624])\n",
      "tensor([-3071.3806,  1990.2921])\n",
      "tensor([-265.6804, -180.5055])\n",
      "tensor([-482.1598,  436.8927])\n",
      "tensor([-118.3257,  -71.9677])\n",
      "tensor([-151.8964,  -45.0712])\n",
      "tensor([-377.5953,  354.5265])\n",
      "tensor([-119.3079,  -72.6800])\n",
      "tensor([-113.3234,  -81.2339])\n",
      "tensor([-90.3127, -15.4398])\n",
      "tensor([-49.8653, -20.9930])\n",
      "tensor([-59.8021, -41.4664])\n",
      "tensor([-1725.3727,  1758.3273])\n",
      "tensor([-154.2256, -100.5138])\n",
      "tensor([-87.8092, -61.6121])\n",
      "tensor([-59.6074, -25.7252])\n",
      "tensor([-45.3708, -30.6699])\n",
      "tensor([-231.1076,  282.8160])\n",
      "tensor([-132.6871,  -85.8380])\n",
      "tensor([-1183.7184,   792.7843])\n",
      "tensor([-161.1257,  -46.4141])\n",
      "tensor([-84.7918, -60.1088])\n",
      "tensor([-37.7037, -12.6399])\n",
      "tensor([-198.9074,  292.2184])\n",
      "tensor([-382.4352,  399.3868])\n",
      "tensor([-43.0604, 260.6605])\n",
      "tensor([-303.5557,  -76.0500])\n",
      "tensor([-142.0621,  -89.3272])\n",
      "tensor([-345.1031,  280.6266])\n",
      "tensor([-597.8551, 1213.5236])\n",
      "tensor([-51.7835, -26.5470])\n",
      "tensor([-107.5728,  -63.6830])\n",
      "tensor([-137.8224,  -86.6051])\n",
      "tensor([-218.1940,  310.2072])\n",
      "tensor([-470.8063,  568.7706])\n",
      "tensor([-519.1539,  403.1525])\n",
      "tensor([-66.8274, -30.3956])\n",
      "tensor([-210.8598,  158.8873])\n",
      "tensor([-108.4850,  275.7169])\n",
      "tensor([-253.5894, -177.9089])\n",
      "tensor([-83.3226, 155.1353])\n",
      "tensor([-222.9369, -151.3749])\n",
      "tensor([-107.6972,  -77.1877])\n",
      "tensor([-108.9972,  -51.9483])\n",
      "tensor([-155.0762,  -86.0639])\n",
      "tensor([-79.1640, -37.7026])\n",
      "tensor([-150.7113,   56.0253])\n",
      "tensor([-98.8101, -59.5176])\n",
      "tensor([-99.5822, -54.2414])\n",
      "tensor([-107.4359,  -56.6290])\n",
      "tensor([-159.3988,  -93.1997])\n",
      "tensor([-508.4210,  187.7955])\n",
      "tensor([-920.7916,  747.6027])\n",
      "tensor([-426.0221,  472.9191])\n",
      "tensor([-686.0548,  -98.7919])\n",
      "tensor([-312.8693,  206.2970])\n",
      "tensor([-100.7013,  -19.1479])\n",
      "tensor([-301.0503, -168.9676])\n",
      "tensor([-52.0968, 275.3695])\n",
      "tensor([ -3.7909, 248.4424])\n",
      "tensor([-90.2805, -63.5624])\n",
      "tensor([-100.6791,  295.0243])\n",
      "tensor([-71.6960, -33.3314])\n",
      "tensor([-252.1810,   23.7230])\n",
      "tensor([-292.0908, -130.7733])\n",
      "tensor([-528.0494,  -29.0941])\n",
      "tensor([-771.3815,  378.9708])\n",
      "tensor([-373.1344,  326.9088])\n",
      "tensor([ 20.6208, 256.3347])\n",
      "tensor([-45.9206, -30.8027])\n",
      "tensor([-152.5952, -109.9518])\n",
      "tensor([-101.0122,  -61.2271])\n",
      "tensor([-95.3875, -68.0491])\n",
      "tensor([-24.8812, 324.7399])\n",
      "tensor([-91.6220, -64.6508])\n",
      "tensor([-499.2296,  365.6173])\n",
      "tensor([-65.7329, -29.2971])\n",
      "tensor([-219.1048,  -80.1907])\n",
      "tensor([-71.9857, -30.9835])\n",
      "tensor([-52.8547, -28.7749])\n",
      "tensor([-2005.9723,  1078.5245])\n",
      "tensor([-111.7461,  -51.5783])\n",
      "tensor([-109.6097,  -67.4913])\n",
      "tensor([-241.6642,   44.4166])\n",
      "tensor([-81.0341, 309.4240])\n",
      "tensor([-116.6345,  -73.8769])\n",
      "tensor([-116.9430,  -83.1338])\n",
      "tensor([-595.1119,  665.5675])\n",
      "tensor([-173.0355,  248.3905])\n",
      "tensor([-185.0574, -135.4514])\n",
      "tensor([-66.6188, -28.9505])\n",
      "tensor([-395.0841,  149.6925])\n",
      "tensor([-165.8715,  -40.5114])\n",
      "tensor([-63.3559, -29.4264])\n",
      "tensor([-1772.1871,  1265.6281])\n",
      "tensor([-156.9550,  178.9733])\n",
      "tensor([-85.6942, -60.5568])\n",
      "tensor([-176.5601,  -81.2937])\n",
      "tensor([ 19.7042, 336.7382])\n",
      "tensor([-772.9967,  173.7404])\n",
      "tensor([-840.6285,  -43.6058])\n",
      "tensor([-64.2161, -10.3051])\n",
      "tensor([-113.3375,  271.4576])\n",
      "tensor([-72.5329, -42.3676])\n",
      "tensor([-589.8612, -383.8748])\n",
      "tensor([-63.8799, -27.6761])\n",
      "tensor([-145.9624,  -62.1688])\n",
      "tensor([-46.2650, 270.9613])\n",
      "tensor([-140.4619,  -92.5129])\n",
      "tensor([-76.1908, 276.7372])\n",
      "tensor([-227.0990,   54.8143])\n",
      "tensor([-184.7041, -135.0837])\n",
      "tensor([-64.9808,  -4.5330])\n",
      "tensor([-23.8580, 269.3488])\n",
      "tensor([-418.0748,  425.8517])\n",
      "tensor([-1092.6500,   768.5460])\n",
      "tensor([-111.1447,  280.4083])\n",
      "tensor([-63.2646, -24.1482])\n",
      "tensor([-82.6266,  57.1018])\n",
      "tensor([-469.6910,  760.7286])\n",
      "tensor([-117.9898,  -58.4098])\n",
      "tensor([-58.1880, -38.4193])\n",
      "tensor([-1278.2164,  1195.9581])\n",
      "tensor([-475.5455,  185.9889])\n",
      "tensor([-61.5563, -14.3967])\n",
      "tensor([-111.2717,  -79.1017])\n",
      "tensor([ 16.9523, 340.8824])\n",
      "tensor([-1246.0270,  1539.4952])\n",
      "tensor([-262.1105,  457.6124])\n",
      "tensor([-654.2809,   15.9752])\n",
      "tensor([ 13.5279, 239.8657])\n",
      "tensor([-1012.3365,   664.8566])\n",
      "tensor([-95.1148, -65.8969])\n",
      "tensor([-291.3790,  106.6610])\n",
      "tensor([-955.8737,  645.5568])\n",
      "tensor([-57.9748, -25.4365])\n",
      "tensor([-246.5639, -108.2017])\n",
      "tensor([-70.0278,  -2.4475])\n",
      "tensor([-542.9821,  279.0426])\n",
      "tensor([-384.1368,  -11.4484])\n",
      "tensor([-51.9782, 321.6381])\n",
      "tensor([-54.7938, -37.4275])\n",
      "tensor([-102.1639,  -50.2145])\n",
      "tensor([-928.8746, -105.9369])\n",
      "tensor([-108.9922,  -74.1704])\n",
      "tensor([-346.4659, -134.3556])\n",
      "tensor([-49.2038, -15.8154])\n",
      "tensor([-48.2976, -32.2075])\n",
      "tensor([-76.8411, -53.0042])\n",
      "tensor([-415.6105,   23.8864])\n",
      "tensor([-103.3850,  -73.7462])\n",
      "tensor([-38.1074,  -7.7721])\n",
      "tensor([-66.1821, -27.8275])\n",
      "tensor([-553.5265,  212.3204])\n",
      "tensor([-161.6876,  -61.5103])\n",
      "tensor([-234.4240, -118.7623])\n",
      "tensor([-56.8440, -24.5057])\n",
      "tensor([-814.4186,  751.4308])\n",
      "tensor([-65.8672, -24.5526])\n",
      "tensor([-143.4421, -101.3471])\n",
      "tensor([-155.2870,  127.0538])\n",
      "tensor([-114.3870,  -81.9874])\n",
      "tensor([-83.7385, -49.0731])\n",
      "tensor([-102.1311,  -72.9545])\n",
      "tensor([-145.3031, -105.0555])\n",
      "tensor([-68.4030, -32.6851])\n",
      "tensor([-546.5319,  408.8478])\n",
      "tensor([-5348.6147,  4109.8584])\n",
      "tensor([-80.9342, 306.5299])\n",
      "tensor([-509.9581,   20.7247])\n",
      "tensor([-71.6802, -49.3883])\n",
      "tensor([  0.2659, 247.3542])\n",
      "tensor([-543.7360,  157.9240])\n",
      "tensor([-74.0473, -24.7335])\n",
      "tensor([-58.3970, -25.9282])\n",
      "tensor([-108.4214,  -51.8609])\n",
      "tensor([-61.5441, 151.5173])\n",
      "tensor([-78.7523, -38.2850])\n",
      "tensor([-203.9047,  153.9237])\n",
      "tensor([-63.1213, -26.9148])\n",
      "tensor([-101.5817,  385.4396])\n",
      "tensor([-56.7263, -22.2268])\n",
      "tensor([ 53.0074, 229.1313])\n",
      "tensor([-64.3723, -12.0213])\n",
      "tensor([-175.0535,   31.5920])\n",
      "tensor([-106.0517,  -64.4629])\n",
      "tensor([-93.8865, -65.8003])\n",
      "tensor([-97.0931, -57.1213])\n",
      "tensor([-180.8283, -119.1768])\n",
      "tensor([-177.7619,  251.5155])\n",
      "tensor([-58.2286, -24.0179])\n",
      "tensor([-88.1502, -41.3937])\n",
      "tensor([-167.2821,  -36.8327])\n",
      "tensor([-118.0086,  -73.2540])\n",
      "tensor([-90.7544, -36.4460])\n",
      "tensor([-505.3517,  200.0216])\n",
      "tensor([-41.9800, -13.4916])\n",
      "tensor([-81.0663, -48.0213])\n",
      "tensor([-275.5995,   28.1259])\n",
      "tensor([-102.4505,  -63.2489])\n",
      "tensor([-44.1784, -22.8007])\n",
      "tensor([-443.0592, -248.1598])\n",
      "tensor([-94.4250, -54.9245])\n",
      "tensor([-74.8272, -31.0635])\n",
      "tensor([ -1.8595, 248.0043])\n",
      "tensor([ 13.5555, 252.4255])\n",
      "tensor([-165.6315,  247.4703])\n",
      "tensor([-184.7051,  -43.4308])\n",
      "tensor([-181.6611,  -96.9618])\n",
      "tensor([-257.4443, -143.5270])\n",
      "tensor([-197.0075, -119.4783])\n",
      "tensor([-72.5456, -20.6204])\n",
      "tensor([-131.4397,  -80.2414])\n",
      "tensor([-76.0526, -32.3413])\n",
      "tensor([-131.4915,  -46.0359])\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(X_test):\n",
    "        print(model(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# predict classifcation - to buy or not to buy\n",
    "pred2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(X_test):\n",
    "        pred = model(data)\n",
    "        pred2.append(pred.argmax().item())\n",
    "        print(pred.argmax().item()) # argmax returns index with maximum value; item returns 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 126]\n",
      " [  0 147]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       126\n",
      "           1       0.54      1.00      0.70       147\n",
      "\n",
      "    accuracy                           0.54       273\n",
      "   macro avg       0.27      0.50      0.35       273\n",
      "weighted avg       0.29      0.54      0.38       273\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15714\\anaconda3\\envs\\fastai_v1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(y_test,pred2))\n",
    "print(classification_report(y_test,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai v1",
   "language": "python",
   "name": "fastai_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
